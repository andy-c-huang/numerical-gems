{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differential geometric formulation\n",
    "Consider a manifold $M$ and two functions $f,g \\in \\mathcal{C}^1(M,\\mathbb{R})$. We consider the constrained optimization problem\n",
    "\n",
    "$$\\begin{aligned}\n",
    "& \\underset{x\\in \\mathbb{R}^m}{\\text{maximize}}\n",
    "& & f(x) \\\\\n",
    "& \\text{subject to}\n",
    "& & g(x) = 0\n",
    "\\end{aligned}$$\n",
    "\n",
    "Observe that the equation $g=0$ defines a submanifold $N$ of $M$. Hence, $f$ is critical at a point $x_0\\in N$ precisely when the covariant derivative $\\nabla ^N$ of $f$ at $x_0$ vanishes, i.e., $\\left.d^N(\\left.f\\right|_N)\\right|_{x_0} = 0$. This is equivalent to saying that, for every tangent vector $\\nu\\in T_{x_0}N$, we have $\\left.df\\right|_{x_0}(\\nu) = 0$. Thus,\n",
    "\n",
    "$$T_{x_0}N \\leqslant \\ker\\left(\\left.df\\right|_{x_0}\\right)$$\n",
    "\n",
    "Geometric interpretation: the vectors $dg\\left(\\partial_{x^1}\\right) , \\ldots , dg\\left(\\partial_{x^m}\\right)$ span $T_{x_0} N$, so this equivalently means that $\\left\\langle \\left.dg\\right|_{x_0}\\left(\\partial_{x^1}\\right), \\ldots , \\left.dg\\right|_{x_0}\\left(\\partial_{x^m}\\right)\\right\\rangle \\leqslant \\ker\\left(\\left.df\\right|_{x_0}\\right)$.\n",
    "\n",
    "Since $N$ is defined by $g=0$, we have \n",
    "\n",
    "$$T_{x_0}N = \\ker(\\left.dg\\right|_{x_0})$$\n",
    "\n",
    "And so,\n",
    "\n",
    "$$\\ker\\left(\\left.dg\\right|_{x_0}\\right) \\leqslant \\ker\\left(\\left.df\\right|_{x_0}\\right) $$\n",
    "i.e., $$\\forall \\eta \\in T_{x_0}N, \\hskip 12pt dg(\\eta)=0 \\hskip 5pt \\Rightarrow \\hskip 5pt df(\\eta)=0$$ \n",
    "\n",
    "To consolidate this expression further, we compute locally. We can express $dg$ and $df$ as\n",
    "\n",
    "$$dg = \\frac{\\partial g}{\\partial x^i} dx^i \\hskip 48pt df = \\frac{\\partial f}{\\partial x^i} dx^i$$\n",
    "\n",
    "For a tangent vector $\\eta = \\eta ^i \\partial _{x^i} \\in T_{x_0}N$, we have\n",
    "\n",
    "$$ dg(\\eta) = \\frac{\\partial g}{\\partial x^i} \\eta^i = \\begin{bmatrix}\\frac{\\partial g}{\\partial x^1} & \\cdots & \\frac{\\partial g}{\\partial x^m}\\end{bmatrix} \\begin{bmatrix} \\eta^1 \\\\ \\vdots \\\\ \\eta ^m \\end{bmatrix} = \\left\\langle \\left(\\left.dg\\right|_{x_0}\\right)^\\#,\\eta \\right\\rangle_M$$\n",
    "$$df(\\eta) = \\frac{\\partial f}{\\partial x^i} \\eta^i = \\begin{bmatrix}\\frac{\\partial f}{\\partial x^1} & \\cdots & \\frac{\\partial f}{\\partial x^m}\\end{bmatrix} \\begin{bmatrix} \\eta^1 \\\\ \\vdots \\\\ \\eta ^m \\end{bmatrix} = \\left\\langle \\left(\\left.df\\right|_{x_0}\\right)^\\#,\\eta \\right\\rangle_M$$\n",
    "\n",
    "\n",
    "Thus, the vectors $\\left(dg|_{x_0}\\right)^\\#$ and $\\left(df|_{x_0}\\right)^\\#$ must parallel because we are in a single dimension, i.e.,\n",
    "\n",
    "$$ \\boxed{ dg_{x_0} \\wedge df_{x_0} =0 \\in \\bigwedge ^2 T^*_{x_0}M }$$\n",
    "\n",
    "Note that the classical Lagrange multiplier $\\lambda$ is implicit in this condition, because the parallel condition at $x_0$ exactly means $ \\exists \\lambda \\mbox{ s.t. }\\lambda \\cdot \\nabla g_{x_0} =  \\nabla f_{x_0} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
